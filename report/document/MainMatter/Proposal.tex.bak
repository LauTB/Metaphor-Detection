\chapter{Marco teórico}\label{chapter:proposal}
En este capítulo se explican los basamentos teóricos que se utilizaron para realizar la tesis desde el punto de vista computacional. Se describen las redes neuronales y los tipos de capas utilizados, al igual que cómo funcionan.
\section{Representación del texto}
Cuando se va a trabajar con texto es necesario encontrar una representación adecuada del mismo. Existen diversas formas de representar texto, entre ellas dos de las más populares son las bolsas de palabras y los \textit{word embeddings}. \\
Las bolsas de palabras (bag of words o representación one-shot) son un vector binario del tamaño del vocabulario donde cada componente representa un término. Si una componente del vector tiene valor $1$ es porque la palabra asociada al índice de dicha componente está presente, en otro caso será $0$. La ventaja principal de es la simplicidad de representación. La mayor desventaja se encuentran el gran tamaño de los vectores a los cuales tendrán la mayoría de las componentes nulas; la otra desventaja es que se pierde el orden de las palabras.\\
Por otra parte, los \textit{word embeddings} son un conjunto de técnicas que buscan representar el texto con vectores de números reales de manera tal que si dos vectores son cercanos es posible decir que tienen significados similares. La idea más importante en esta representación es tener una representación densa, o sea, que haya la menor cantidad de componentes nulas en el vector que se obtiene. Usualmente la dimensión de los vectores se encuentra en la escala de los cientos, una reducción considerable comparada con la dimensión que sería necesaria en la representación binaria.\\
Los algoritmos para obtener \textit{word embeddings} aprenden a partir de corpus de texto con un tamaño de vocabulario predeterminado. El método de aprendizaje suele ser mediante redes neuronales o con enfoques estadísticos como extracción de características o features. \\
Uno de los enfoques más usados para entrenar es \textit{word2vec} \cite{Mikolov}, el cual se basa en diseñar una red neuronal que sea alimentada con un corpus de texto. Hay dos vías que puede usar el modelo para aprender, \textit{Continuous Bag-of-Words (CBOW)} donde aprende la representación de una palabra en base al contexto que la rodea, por otra parte, el \textit{Continuous Skip-Gram Model} aprende la representación de las palabras que rodean un término a partir del mismo. \\
En esta investigación se utilizaron word embeddings entrenados de antemano por [\cite{MikolovetAl}], que se basaron en el enfoque \textit{word2vec} particularmente utilizando \textit{CBOW}. Se utilizan estos embeddings ya que fueron entrenados con texto extraído de Wikipedia por lo que puede esperarse diversidad en el vocabulario que se encuentra representado. \\


\section{Aprendizaje automático y redes neuronales}
En el capítulo anterior se explicó que uno de los enfoques para trabajar con las metáforas es el basado en corpus. Eso generalmente implica el uso de técnicas de aprendizaje automático, particularmente, aprendizaje supervisado, para producir modelos entrenados en una tarea determinada.
\subsection{Redes neuronales}
Una red neuronal es un tipo de modelo que se utiliza para realizar aprendizaje supervisado, se inspira en la forma que funciona el cerebro humano. Consiste en un conjunto de neuronas organizadas por capas, cada neurona posee una entrada y una salida mediante conexiones con otras neuronas. Dichas conexiones tienen pesos propios, de ahí que una red neuronal sea comparada con un grafo dirigido ponderado.\\
Cuando una neurona recibe información realiza una suma de cada valor recibido multiplicándolo por el peso de la arista por la que lo recibió, o sea, una suma ponderada y luego suma un valor de sesgo propio de la neurona, una vez tiene ese valor se aplica una función, este valor se conoce como la activación de una neurona y representa la entrada que recibirán las neuronas conectadas a esta en la próxima capa. Con ese enfoque es usual ver que las neuronas sean definidas como funciones\\
El proceso de aprendizaje de la red consiste en ajustar los pesos y sesgos de todas las aristas y neuronas de la red de forma tal que sea capaz de dar la salida deseada. Para ello en la fase de entrenamiento la red es alimentada con ejemplos de los que se conoce el resultado correcto, cuando la red devuelve un resultado se calcula el error que cometió la red con el objetivo de minimizar el error mediante descenso por gradientes para saber cuáles son los pesos y sesgos que deben ser ajustados, el algoritmo utilizado para esto se conoce como backpropagation.
\subsection{RNN}
Una red neuronal recurrente(RNN, por sus siglas en inglés) se diferencia de una red neuronal común en que permite usar como entrada la salida de estados anteriores mientras mantiene estados ocultos. Eso significa que en la representación de grafos de una red neuronal, una red recurrente tendría ciclos. Adicionalmente a lo descrito previamente, una red recurrente posee memoria que guarda lo que se tiene computado hasta el momento y lo utiliza para computar el próximo paso.\\
Una red recurrente convierte las activaciones independientes en dependientes al darles los mismos pesos y sesgos a las neuronas involucradas, lo cual conlleva a la unificación de las capas de dichas neuronas como una sola capa recurrente.\\
Para entrenar se calcula el estado actual de la red en función de la entrada y el estado anterior, este proceso se repite por cada estado que se ha guardado. Una vez se computa el estado actual, se produce la salida en función a ese estado y se calcula la pérdida para realizar backpropagation.\\ 
 Generalmente son utilizadas para tareas de NLP porque ofrecen ventajas como la posibilidad de procesar entradas de cualquier tamaño. Otra de sus principales ventajas es que permite que se tome en cuenta información pasada en el momento de computar. Un caso particular de esto es el trabajo de [\cite{Ye}], donde se utilizan redes recurrentes para encontrar la similitud entre preguntas.\\
Entre sus principales desventajas están el aumento del tiempo de cómputo necesario para entrenar y la dificultad para acceder a información de hace mucho tiempo. Esta última es la causa del fenómeno conocido como desvanecimiento del gradiente.\footnote{https://mlearninglab.com/2018/05/06/problema-de-desvanecimiento-del-gradiente-vanishing-gradient-problem/}
\subsection{GRU}
Una red GRU(Gated Recurrent Unit) es un tipo de red neuronal diseñada específicamente para contrarrestar el problema del desvanecimiento del gradiente. Para ello utilizan lo que se conoce como la "compuerta de actualización " y la "compuerta de reseteo " que son dos vectores que deciden cuánta de la información recibida se volverá salida, de la forma descrita en \ref{Fig:gru}. \\
\begin{figure}[htb]\label{Fig:gru}
\includegraphics[scale= 0.5]{Graphics/gru.png}
\caption{Estructura de una unidad GRU. Fuente: https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be}
\end{figure}
La compuerta de actualización es la primera parte de la figura y se representa con $z_{t}$, donde se recibe el estado anterior ($h_{t-1}$) y su valor es $z_{t} = \sigma\left(W^{\left(z\right)}x_{t}+U^{\left(z\right)}h_{t-1}\right)$, donde $x_{t}$ es la entrada del modelo, $W^{\left(z\right)}$ representa los pesos aprendidos hasta el momento asociados a la entrada y $U^{\left(z\right)}$ representa los pesos asociados a los estados. Esta compuerta de reseteo permite decidir cuanta información de los estados anteriores debe ser conservada.\\
La compuerta de reseteo, representada por $r_{t}$, se encarga de decidir cuanta información anterior será descartada y su valor es $z_{t} = \sigma\left(W^{\left(r\right)}x_{t}+U^{\left(r\right)}h_{t-1}\right)$.\\
Una vez se tienen las compuertas calculadas el próximo paso es calcular el estado actual de la memoria $h\prime_{t} = \tanh\left(Wx_{t}+r_{t} \odot Uh_{t-1}\right)$, donde se queda guardado el estado actual tras usar la compuerta de reseteo.\\
Finalmente, se calcula la salida $h_{t} = z_{t}\odot h_{t-1} + \left(1-z_{t}\right) \odot h\prime_{t}$.\\
Gracias a el uso de estas compuertas se supera la dificultad de las RNN con la desaparición del gradiente, manteniendo el resto de las ventajas mencionadas. \\
En el trabajo de [\cite{Liu}] se utilizó este tipo de capa, en combinación con redes convolucionales, para extracción de características semánticas en textos chinos.

\subsection{LSTM}
Las redes LSTM(Long Short-Term Memory) son una generalización de GRU por lo que resuelven el mismo problema. En este caso se tienen tres compuertas: "la compuerta de olvidar", "la compuerta de entrada", "la compuerta de salida" y el estado de la unidad.\\
La compuerta de olvidar decide que información olvidar y cuál conservar. Recibe dos entradas: el estado oculto anterior y la entrada actual. Para procesar las entradas les aplica la función sigmoidal, mientras más cercano a 1 sea el valor obtenido más se conserva y si es más cercano a 0 se descarta.\\
La compuerta de entrada decide qué información importante debe agregar al estado de la celda en función de las entradas anteriores. Para actualizar el estado de la celda, se pasa el estado oculto anterior  y la entrada actual  a una función sigmoidea. Eso decide qué valores se actualizarán transformando los valores para que estén entre 0 y 1. 0 significa que no es importante y 1 significa que es importante. también se pasa el estado oculto y la entrada actual a la función tanh para reducir los valores entre -1 y 1 para ayudar a regular la red. Luego se multiplica la salida de tanh con la salida sigmoidea. La salida sigmoidea decidirá qué información es importante mantener de la salida tanh.\\
Con lo calculado previamente se tiene suficiente información para calcular el estado de la celda. Primero, el estado de la celda se multiplica puntualmente por el vector obtenido de la puerta de olvidar. Esto tiene la posibilidad de eliminar valores en el estado de la celda si se multiplica por valores cercanos a 0. Luego se toma la salida de la puerta de entrada y se hace una suma puntual que actualiza el estado de la celda a nuevos valores que la red neuronal considera relevantes. Eso devuelve el nuevo estado de la celda.\\
Por último está la puerta de salida. La puerta de salida decide cuál debería ser el siguiente estado oculto que contiene información sobre entradas anteriores. El estado oculto también se usa para predicciones. Primero, se pasa el estado oculto anterior y la entrada actual a una función sigmoidal. Luego se pasa el estado de celda recién modificado a la función tanh. Se multiplica la salida de tanh con la salida sigmoidea para decidir qué información debe llevar el estado oculto. La salida es el estado oculto. El nuevo estado de celda y el nuevo oculto se transfieren al siguiente paso de tiempo.\\
El proceso descrito previamente puede verse en la \ref{Fig:lstm}.
\begin{figure}[htb]\label{Fig:lstm}
\includegraphics[scale= 0.6]{Graphics/lstm.png}
\caption{Estructura de una unidad LSTM. Fuente: https://towardsdatascience.com/lstm-recurrent-neural-networks-how-to-teach-a-network-to-remember-the-past-55e54c2ff22e}
\end{figure}
Con este tipo de capa se han realizado diversos estudios del lenguaje como el de [\cite{Jelodar}], en el cual se revisan textos relacionados al COVID-19 para realizar clasificación del sentimiento.\\
Este tipo de capa es particularmente buena para trabajar con texto y secuencias, de ahí que fueran el seleccionados para la experimentación.

\section{Funciones específicas del modelo}
Cuando se explicó sobre las redes neuronales se mencionó que luego de la suma ponderada de la entrada y el sesgo se aplica una función, dicha función se conoce como función de activación. El objetivo de esta función que la transformación que ocurre entre los valores de entrada y salida sea no linear, lo cual conlleva a poder atacar problemas más diversos. Existen diversas funciones que pueden usarse para este propósito, a continuación se presentan las dos que se utilizan en los modelos que se utilizaron.\\

La función tangente hiperbólica( $\tanh$) es similar a la función sigmoidal, la única diferencia es que $\tanh$ varía entre $-1$ y $1$. Con esta función, mientras más grande sea el valor de entrada más cercano será a $1$, por el contrario, mientras más pequeño sea el valor de entrada más cercano será a $-1$. Tiene la ventaja de que al estar centrada en $0$ es posible ver los valores de activación como neutros, muy positivos o muy negativos.\\

La otra función de activación utilizada es softmax, esta función se describe como la combinación de múltiples sigmoidales. Calcula la probabilidad relativa de que un elemento pertenezca a determinada clase y, como resultado de ser múltiples funciones sigmoidales, la suma de dichas probabilidades no necesariamente será 1. Esta función suele usarse en problemas de clasificación en varias clases.\\
Otra cosa que se mencionó a la hora de explicar las redes neuronales fue la existencia de una pérdida. Cuando se define un modelo de red neuronal es importante definir una función con la que se calcula dicha pérdida, de ahí que a dichas funciones se les conozca como funciones de pérdida. Existen diversos tipos de funciones de pérdida según el tipo de problema que se busque resolver. En el caso de los modelos creados, se necesita una función que sea compatible con clasificar la entrada en dos clases (metáfora o no metáfora), la función que se utiliza en estos casos se conoce como \textit{Categorical crossentropy}.