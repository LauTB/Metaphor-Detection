\chapter{Experimentos}\label{chapter:implementation}
En este capítulo se presentan los modelos realizados y la experimentación realizada con ellos. Además se discuten detalles de implementación y los resultados obtenidos.
\section{Los datos}
El corpus utilizado para entrenar es el [\cite{Tsvetkov}] el cual se encuentra en inglés y tiene la siguiente forma:
\begin{center}
 ADJETIVO SUSTANTIVO ETIQUETA
\end{center}
La etiqueta es binaria representando si se está en presencia de una metáfora o no.\\
Inicialmente, se contaban con 200 ejemplos de parejas adjetivo- sustantivo. Esa cantidad de ejemplos no sería suficiente para entrenar un modelo. La solución a la dificultad planteada fue aumentar los datos utilizando sinónimos. Dado que la carga metafórica se encontraba en el adjetivo, se buscaron sinónimos del sustantivo y se añadieron al corpus los nuevos pares generados con la misma etiqueta. La herramienta utilizada para esto fue Word Net [\cite{Miller}] vía la biblioteca de Python nltk[\cite{Bird}]. Usando esta técnica se obtuvieron un total de 1462 pares(700 negativos y 762 positivos). Del corpus construido se utilizó el 80\% para entrenar y el 20\% para evaluar.\\
Tras obtener más datos, el próximo paso fue convertir cada par en su representación vectorial. Para ello, se utilizaron los \textit{word embeddings} de [\cite{MikolovetAl}], los cuales tienen 300 dimensiones.\\
Usualmente, para trabajar con \textit{word embeddings} les necesario tener alta potencia de cómputo por el gran tamaño del archivo binario (u otro formato). En este caso no que necesario contar con una computadora de altas prestaciones, gracias a la biblioteca \textit{PyMagnitude} la cual cuenta con un algoritmo de compresión especializado para \textit{word embeddings}. Gracias a dicha compresión fue posible representar el corpus como vectores. Estos datos se usaron para el train y test de los modelos.\\
 Dado el gran tamaño que tienen los archivos de los embeddings no fueron incluidos en el repositorio de GitHub, ya que este sitio tiene restricciones para archivos de tamaño superior a 1 GB.\\

Los datos con los que se realizó la validación fueron del corpus CoMeta [\cite{Sánchez}]. Este corpus posee diversos tipos de metáforas lexicográficas, por lo que fue necesario extraer los pares adjetivo sustantivo con sus respectivas etiquetas. De esa extracción se obtuvieron 205 pares etiquetados. Dichos pares pares se llevaron al idioma inglés con el paquete googletrans\footnote{https://travis-ci.org/github/ssut/py-googletrans} antes de aplicar los \textit{word embeddings} y evaluarlos en el modelo. \\
La herramienta de traducción automática utilizada se basa en el traductor online Google Translate que, según los blogs del sitio\footnote{https://translatepress.com/is-google-translate-correct}, tiene un $ 94\% $ de precisión con el idioma español.

\section{Los modelos}
Ambos modelos fueron creados utilizando Tensorflow [\cite{tensorflow2015-whitepaper}] .
El primer modelo consiste en tres capas una capa de entrada, una capa bidireccional LSTM y una capa de salida, como se aprecia en la Figura 3.1. La función de pérdida es Categorical Crossentropy y la función de activación softmax que ya fueron explicadas en el capítulo anterior. \\
\begin{figure}[htb]\label{Fig:lstm_mod}
\includegraphics[scale= 0.6]{Graphics/lstm_metaphor_model.png}
\caption{Arquitectura del modelo LSTM}
\end{figure}
\begin{table}[hbt]
\centering
\begin{tabular}{c|c|c|c}
Épocas & F1 & Precisión & Recobrado\\
\hline
5 & 0.7148 & 0.5767 & 0.9552\\
\hline
7 & 0.7176 & 0.5788 & 0.9607\\
\hline
10 & 0.7175 & 0.5782 & 0.9607\\
\hline
\end{tabular}
\caption{Experimentos con el modelo LSTM \label{Tabla:1}}
\end{table}

La Tabla 1 muestra los resultados obtenidos, donde puede apreciarse que la diferencia entre usar 7 y 10 épocas no es significativa, sin embargo, el modelo presenta mejoría con respecto a usar 5 épocas. Se puede apreciar también una diferencia elevada entre el valor de la precisión y el recobrado, una posible causa es el mayor número de ejemplos positivos en el corpus por lo que es posible que el modelo sea más propenso a dar falsos positivos.\\
El segundo modelo es similar de primero, las principales diferencias están en que el en este modelo, la segunda capa es una capa GRU y la función de activación es tangente hiperbólica, la Figura 3.2 muestra su arquitectura. La Tabla 2 muestra los resultados obtenidos utilizando la misma cantidad de épocas que en el caso anterior.\\

\begin{figure}[htb]\label{Fig:gru_mod}
\includegraphics[scale= 0.6]{Graphics/gru_metaphor_model.png}
\caption{Arquitectura del modelo GRU}
\end{figure}
\begin{table}[htb]%
\centering
\begin{tabular}{c|c|c|c}
Épocas & F1 & Precisión & Recobrado\\
\hline
5 & 0.6304 & 0.4663 & 0.9833\\
\hline
7 & 0.5460 & 0.3912 & 0. 9264\\
\hline
10 & 0.5959 & 0.5730 & 0.6387\\
\hline
\end{tabular}
\caption{Experimentos con el modelo GRU \label{Tabla:2}}%
\end{table}
Con este modelo se aprecia que, cuando se entrenan 10 épocas, el recobrado es menor que en su contraparte LSTM por lo que es probable que tenga menos falsos positivos, lo cuál sería una mejora.\\

Como forma de validación, se evaluaron los modelos con el Corpus CoMeta [\cite{Sánchez}], el cual se procesó de la manera descrita en la sección anterior. La Tabla 3 muestra los resultados obtenidos en comparación con el experimento realizado en el [\cite{Sánchez}] con traducción automática al inglés.\\
\begin{table}[htb]%
\centering
\begin{tabular}{c|c|c|c|c}
Modelo & Épocas & F1 & Precisión & Recobrado\\
\hline
CoMeta & 10 & 0.3346 & 0.2324 & 0.5972\\
\hline
LSTM & 10 & 0.2684 & 0.1618 & 0.8435\\
\hline
GRU & 10 & 0.2171 & 0.1580 & 0.3469\\
\hline
\end{tabular}
\caption{Comparaciones con el estado del arte de CoMeta \label{Tabla:3}}%
\end{table}

Estos resultados no son completamente comparables ya que el experimento del CoMeta contiene metáforas de más tipos y eso sin dudas afecta los valores de las métricas.
\section{Construcción de un corpus con el modelo}
El objetivo de crear un modelo siempre fue utilizarlo para construir un corpus con datos en español, en este caso, se utilizó el modelo LSTM descrito previamente.  Los datos en español se obtuvieron del periódico Vanguardia, de la provincia Villa Clara, dicho periódico fue seleccionado como fuente de datos ya que es de interés para el proyecto CORESPUC. Para extraerlos se utilizó el paquete Scrapy. También se usó dicho paquete para extraer las versiones digitalizadas en PDF del periódico físico. \\
Una vez se tuvieron los textos a procesar se utilizó el paquete Spacy [\cite{spacy2}] para obtener la etiqueta POS (\textit{Part of speech} o parte del discurso) a cada oración y, posteriormente, extraer los pares adjetivo-sustantivo que estuvieran presentes en cada oración. Se obtuvieron 9186 pares con este proceso.\\
Finalmente, se utilizó el paquete googletrans para llevar los pares del español al inglés. Debido a este proceso de traducción, 366 pares se volvieron frases de más palabras en inglés y, por tanto, fueron descartadas. El resto de los pares fue representado con los \textit{embeddings} y obtuvo una etiqueta sobre su carga metafórica.\\
